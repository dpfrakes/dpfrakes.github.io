<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ethics on Dan Frakes</title>
    <link>https://dpfrakes.github.io/tags/ethics/</link>
    <description>Recent content in ethics on Dan Frakes</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://dpfrakes.github.io/tags/ethics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Business Ethics</title>
      <link>https://dpfrakes.github.io/posts/decision-and-ethics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dpfrakes.github.io/posts/decision-and-ethics/</guid>
      <description>Decision making should remain with people. Data gathering, analysis, and even recommendations may (and in many cases, should) fall to technology, including AI, but people should always be the one to pull the trigger - metaphorically and certainly literally.
Business idea: the differentiating factor for Frakes, Inc. is that we will always reserve the right to revoke our customers&#39; rights. Obviously this is not because we&amp;rsquo;d ever want to, but because we don&amp;rsquo;t want to be like Apple.</description>
    </item>
    
    <item>
      <title>Machine Learning Hasn&#39;t Failed Us, We Have</title>
      <link>https://dpfrakes.github.io/posts/ml-hasnt-failed-us/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dpfrakes.github.io/posts/ml-hasnt-failed-us/</guid>
      <description>I was watching a presentation by QuantumBlack, a technology company touting itself as an advocate of &amp;ldquo;augmented intelligence&amp;rdquo; instead of &amp;ldquo;artificial intelligence,&amp;rdquo; at the Royal Institution (link). In it, Martha Imprialou talks about some of the tragedies of poorly-executed implementations of machine learning in our world with a slide titled &amp;ldquo;When machine learning fails to deliver.&amp;rdquo;
The three examples given were:
 A self-driving Uber car hit and killed a pedestrian Amazon&amp;rsquo;s one-day delivery service area excluded ~50% of the black population in Chicago Google&amp;rsquo;s sentiment analyzer rated the terms &amp;ldquo;Jew&amp;rdquo; and &amp;ldquo;homosexual&amp;rdquo; negatively  All three of these incidents are, at best, unfortunate and, at worst, tragedies.</description>
    </item>
    
  </channel>
</rss>
